{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用模型进行情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于yiyanghkust/finbert-tone-chinese 的文本情感分析\n",
    "\n",
    "https://huggingface.co/yiyanghkust/finbert-tone-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)  \n",
    "    print(f\"GPU 型号: {device_name}\")\n",
    "else:\n",
    "    print(\"没有可用的 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "local_model_path = \"models/finbert-tone-chinese\"\n",
    "\n",
    "finbert_tone_chinese_tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "finbert_tone_chinese_model = AutoModelForSequenceClassification.from_pretrained(local_model_path).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    inputs = finbert_tone_chinese_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = finbert_tone_chinese_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy().flatten()\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'finbert_tone_chinese_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "tqdm.pandas(desc=\"Processing sentiment analysis\")\n",
    "\n",
    "input_files = os.listdir(\"batch_save_xlcj_flash\")\n",
    "\n",
    "processed_files = set(os.listdir(output_dir))\n",
    "\n",
    "# Only process files that haven't been processed yet\n",
    "files_to_process = [file for file in input_files if f\"{file}\" not in processed_files]\n",
    "\n",
    "for file in tqdm(files_to_process, desc=\"Processing sentiment analysis\"):\n",
    "    flash_batch_data = pd.read_feather(f\"batch_save_xlcj_flash/{file}\")\n",
    "    flash_batch_data = flash_batch_data.dropna(subset = 'rich_text')\n",
    "    if not flash_batch_data.empty:\n",
    "        flash_batch_data[['Neutral', 'Positive', 'Negative']] = flash_batch_data['rich_text'].apply(lambda x: pd.Series(analyze_sentiment(x)))  # Labels: 0 -> Neutral; 1 -> Positive; 2 -> Negative\n",
    "    \n",
    "        flash_batch_data.to_feather(f\"{output_dir}/{file}\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del finbert_tone_chinese_tokenizer\n",
    "del finbert_tone_chinese_model\n",
    "# 清除缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用Helsinki-NLP/opus-mt-zh-en 将中文翻译为英文之后 再调用原始 FinBERT 进行情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "local_translator_model_path = \"models/opus-mt-zh-en\"\n",
    "\n",
    "translator_tokenizer = MarianTokenizer.from_pretrained(local_translator_model_path)\n",
    "translator_model = MarianMTModel.from_pretrained(local_translator_model_path).to(device)\n",
    "\n",
    "local_finbert_model_path = \"models/FinancialBERT-Sentiment-Analysis\"\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(local_finbert_model_path)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(local_finbert_model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    # 最大长度\n",
    "    max_length = 512\n",
    "\n",
    "    # 将输入文本编码为 token\n",
    "    inputs = translator_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=False)\n",
    "    tokens = inputs[\"input_ids\"][0].tolist()  # 将第一个样本的 token 转为 list\n",
    "\n",
    "    # 按 max_length 分段\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    \n",
    "    translated_texts = []\n",
    "    for chunk in chunks:\n",
    "        # 构建输入张量并移动到 GPU\n",
    "        input_ids = torch.tensor([chunk], dtype=torch.long).to(device)  # 显式指定设备\n",
    "        inputs = {\"input_ids\": input_ids}\n",
    "        \n",
    "        # 翻译\n",
    "        translated_ids = translator_model.generate(**inputs)\n",
    "        translated_text = translator_tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "        translated_texts.append(translated_text)\n",
    "    \n",
    "    # 拼接翻译结果\n",
    "    return \" \".join(translated_texts)\n",
    "\n",
    "# 函数：进行情绪分析\n",
    "def analyze_sentiment(text):\n",
    "    inputs = finbert_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = finbert_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy().flatten()\n",
    "    return probs\n",
    "\n",
    "def process_df(df):\n",
    "    tqdm.pandas()\n",
    "    df['translate_content'] = df['rich_text'].apply(translate_text)\n",
    "    df[['Negative', 'Neutral', 'Positive']] = df['translate_content'].apply(lambda x: pd.Series(analyze_sentiment(x))) # Labels: 0 -> Negative; 1 -> Neutral; 2 -> Positive\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_dir = 'translate_en_finbert_origin_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "tqdm.pandas(desc=\"Processing sentiment analysis\")\n",
    "\n",
    "input_files = os.listdir(\"batch_save_xlcj_flash\")\n",
    "processed_files = set(os.listdir(output_dir))\n",
    "\n",
    "# 记录错误文件列表\n",
    "error_files = []\n",
    "\n",
    "# 持续循环直到处理完所有文件\n",
    "while True:\n",
    "    # 只处理未处理的文件\n",
    "    files_to_process = [file for file in input_files if file not in processed_files]\n",
    "\n",
    "    if not files_to_process:\n",
    "        print(\"所有文件已处理完成。\")\n",
    "        break\n",
    "\n",
    "    for file in tqdm(files_to_process):\n",
    "        try:\n",
    "            flash_batch_data = pd.read_feather(f\"batch_save_xlcj_flash/{file}\")\n",
    "            flash_batch_data = flash_batch_data.dropna(subset=['rich_text'])\n",
    "            if not flash_batch_data.empty:\n",
    "                flash_batch_data_with_senti = process_df(flash_batch_data)\n",
    "                flash_batch_data_with_senti.to_feather(f\"{output_dir}/{file}\")\n",
    "                processed_files.add(file)  # 更新已处理文件集合\n",
    "            else:\n",
    "                print(f\"{file} 是空的，跳过。\")\n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {file} 时发生错误: {e}\")\n",
    "            error_files.append(file)  # 记录发生错误的文件\n",
    "            continue\n",
    "\n",
    "# 输出错误文件列表\n",
    "if error_files:\n",
    "    print(\"以下文件在处理时发生了错误:\")\n",
    "    for error_file in error_files:\n",
    "        print(error_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
